---
title: "Lösungsskizze: Random Forest"
subtitle: "Vorhersage Körperfettanteil"
lang: de
author: "Arbeitsgruppe quantitative Methodenausbildung am ifes"
date: last-modified
format: 
  html:
    toc: true
    html-math-method: katex
  pdf:
    toc: true
    number-sections: false
    colorlinks: true 
    papersize: a4
bibliography: rf-references.bib
---

```{r}
#| label: setup
#| include: false

library(mosaic)
library(here)
library(randomForest)
library(ggplot2)
library(caret)
library(tidyverse)
```

# Einleitung


In dieser Fallstudie werden wir den Random Forest Algorithmus nutzen, um den Körperfettanteil vorherzusagen.
Wir verwenden dazu den Body Fat Datensatz, der verschiedene Messungen wie Gewicht, Größe und Umfänge unterschiedlicher Körperregionen enthält.

Die genaue Bestimmung des Körperfettanteils ist sehr aufwendig und teuer und im Alltag nicht zu vollziehen.
Die Bestimmung des Körperfettanteils eines menschlichen Körpers erfolgte in den vorliegenden Daten mittels der Goldstandardmethode der sog. Unterwasserwägung nach dem archimedischen Prinzip.
Je schwerer jemand unter Wasser ist, desto höher ist die Dichte des Körpers.
Muskeln haben eine höhere Volumendichte als Fettgewebe.
Je höher das Gewicht unter Wasser ist, desto mehr fettfreie Masse hat dieser Körper.

Da eine Unterwasserwägung sehr aufwendig ist und eine große Apparatur benötigt braucht es für den Alltag Parameter, die leicht zu erheben sind.
Mit dieser Fallstudie analysieren wir, welche weiteren, einfacheren anthropometrischen Parameter den Körperfettanteil gut vorhersagen.

Der Datensatz wird aufbereitet, um anthropometrische Parameter aus den Daten zu generieren, die derzeit als aussagekräftig diskutiert werden.

# Entscheidungsbäume (CART)

Um zu verstehen, was der Random-Forest Algorithmus ist und was er macht, ist es zunächst nützlich zu wissen, was Entscheidungsbäume sind.

Entscheidungsbäume basieren auf der Idee komplexe Beziehungen, mithilfe von Daten, in einfache "ja/nein"-Fragen aufzubrechen.
Die Struktur eines Entscheidungsbaumes ergibt sich dabei wie folgt:  
An jedem Knotenpunkt (Node), beginnend mit der Wurzel des Baumes (Root Node), splittet der Entscheidungsbaum die Beobachtungen der Zielvariable (abhängige Variable) anhand der Prädiktorvariablen (unabhängige Variablen) in jeweils zwei Submengen.
Dies passiert so lange, bis ein zuvor definiertes Abbruchkriterium erreicht wird.

Es können zwei Arten von Entscheidungsbäumen unterschieden werden, Klassifikations- und Regressionsbäume (Classification- an Regression Trees - CART).

- **Klassifikationsbäume** werden zur Vorhersage einer kategorialen Zielvariablen verwendet, während
- **Regressionsbäume** zur Vorhersage einer metrischen Zielvariablen eingesetzt werden.  

Der CART-Algorithmus ist nur eine von vielen Methoden, um Entscheidungsbäume zu erzeugen, sie ist aber die Grundlage für viele baumbasierte Machine-Learning-Algorithmen wie Random Forest.

![Quelle: eigene Darstellung](img/Beispiel-Klassifikationsbaum.png)

# Random Forest

Random Forest ist ein von @breiman_random_2001 entwickelter Machine-Learning-Algorithmus, der die Ergebnisse vieler verschiedener Entscheidungsbäume kombiniert, um bestmögliche Vorhersagen zu treffen.

Die Entscheidungungbäume werden dazu auf Basis eines Trainingsdatensatzes erstellt.
Wobei die einzelnen Entscheidungsbäume des RF-Algorithmus auf jeweils leicht verschiedenen Subdatensätzen des ursprünglichen Trainigsdatensatzes trainiert werden.
Diese verschiedenen Subdatensätze werden mithilfe von Bagging (Bootstrap Aggregation) erstellt.
Bagging funktioniert indem eine festgelegte Menge von Bootstrap-Stichproben (d.h. Stichproben der gleichen Größe) durch zufälliges Ziehen von Beobachtungen mit Zurücklegen aus dem Trainigsdatensatz generiert werden.
Damit die Entscheidungsbäume noch verschiedener zueinander werden, werden für die einzelnen Splits der Bäume nicht alle Variablen des Subdatensatzes, auf dem sie trainiert werden, genommen, sondern eine zufällige Teilmenge dieser Variablen.  

Zusammengefasst werden die einzelnen Entscheidungsbäume auf zufällig zusammengesetzten Subdatensätzen, die bei jedem Split eine neue, zufällige Zusammensetzung von Variablen besitzen, erstellt.
Die einzelnen Entscheidungsbäume werden am Ende des Algorithmus zusammengefasst und geben ein Modell zurück, mit dem neue Werte vorhergesagt werden können.

![Quelle: eigene Darstellung](img/RF-Algorithmus.png)

# Daten laden

Als Datengrundlage verwenden wir die Body-Fat-Datentabelle von Kaggle: [Link Body-Fat-Daten](https://www.kaggle.com/datasets/fedesoriano/body-fat-prediction-dataset)

```{r}
#| label: data

# Daten einlesen
bodyfat <- here("data", "Bodyfat.csv") |> read.csv()

# Überblick über die Daten
head(bodyfat)

# Struktur der Daten (bodyfat)
str(bodyfat)

```

------------------------------------------------------------------------

::: {.callout-tip title="Aufgabe & Fragen zum Datensatz"}
1. Verschaffen Sie sich einen Überblick über die Daten.

2. Was ist eine Beobachtungseinheit in diesem Datensatz?

   *Antwort:* Eine Beobachtungseinheit ist ein Mann.

3. Eruieren Sie in welchen Einheiten die Variablen Height, Weight und Abdomen vorliegen.

   *Antwort:* Height -- inches, Weight -- lbs, Abdomen -- cm.
:::

# Berechnung des Körperfettanteils

Der vorliegende Wert des Körperfettanteils im Datensatz wurde aus der ermittelten Dichte mit der Formel nach @siri_gross_1956 berechnet.
Eine Erklärung können Sie bei @rashmi_evaluation_2019 nachlesen.

$$ 
  \text{bodyfat}_{\text{Siri}}[\%] = \left(\frac{4.95}{density} - 4.500\right) \cdot 100
$$

Eine neuere Formel nach @brozek_densitometric_1963 zeigt eine etwas genauere Schätzung des Körperfettanteils (@guerra_accuracy_2010).
Die Formel ist im Folgenden aufgeführt.

$$ 
  \text{bodyfat}_{\text{Brožek}}[\%] = \left(\frac{4.575}{density} - 4.142\right) \cdot 100
$$

Fügen wir die neue Variable mit der Berechnung nach @brozek_densitometric_1963 in die Datentabelle ein:

```{r}
#| label: brozek

# Existierende BodyFat-Variable umbenennen
bodyfat <- bodyfat |> rename(bodyfat_siri = BodyFat)

# Bodyfat nach Brozeck berechnen
bodyfat <- bodyfat |> mutate(
  bodyfat_brozeck = (4.58/Density - 4.142) * 100)
```

Da die Dichtebestimmung sehr aufwendig und teuer ist, werden heute Surrogatparameter zur Bestimmung des Körperfettanteils genutzt, eingie kennen Sie:

- BMI
- Waist-to-Hip Ratio (WHR)
- Waist-to-Height Ratio (WHtR)
- Oberarmumfang

Erstellen wir aus den vorliegenden Daten einige der genannten Parameter und ändern noch relevante Einheiten.

# Datenmanagement

Die Struktur `str()` der Daten ließ bereits vermuten, dass die Körpergröße in \[inch\] und das Gewicht in Pfund \[lbs\] angegeben sind.
Diese Variablen werden in diesem Kapitel in SI-Einheiten umgerechnet.
Zusätzlich werden die oben genannten Parameter berechnet.

## Einheiten umrechnen

### Körpergröße in Meter \[m\]

```{r}
#| label: groesse in m

# Größe umrechnen
bodyfat <- bodyfat |> mutate(
  height_m = round(Height * 0.0254, 2))

# Überprüfen der Eingabe
head(bodyfat$height_m)

# Löschen der alten Variable
bodyfat$Height <- NULL
```

### Gewicht in Kilogramm \[kg\]

```{r}
#| label: weight_kg

# Gewicht umrechnen
bodyfat <- bodyfat |> mutate(
  weight_kg = round(Weight * 0.453592, 1))

# Überprüfen der Eingabe
head(bodyfat$weight_kg, 10)

# Löschen der alten Variable
bodyfat$Weight <- NULL
```

## Surrogatparameter berechnen

### Waist-to-hip-ratio (whr)

Ein Surrogatparameter ist die Waist-to-Hip Ratio.
Um diesen Parameter zu berechnen, wird die Variable `abdomen` in waist umbenannt und die Variable `waist` durch `hip` geteilt:

```{r}
#| label: rename_whr

# abdomen = taille = waist
# Umbenennen der Variablen
bodyfat <- bodyfat |> rename(waist = Abdomen)

# whr berechnen
bodyfat <- bodyfat |> mutate(
  whr = waist/Hip)

# Überprüfen der Eingabe
head(bodyfat$whr)
```

### Waist to height ratio (WHtR)

Ein weiterer Surrogatparameter ist die Waist-to-Height Ratio.

------------------------------------------------------------------------

::: {.callout-tip title="Aufgabe -- Variable WHtR erstellen"}
1. Erstellen Sie eine adäquate Graphik zur Darstellung der Verteilung der Variable Körpergröße.
Welche Verteilung zeigt sich?
  
   *Antwort:* Die Daten zeigen eine rechts symmetrische Verteilung, näherungsweise eine Normalverteilung

2. Erstellen Sie eine neue Variable mit dem Namen `WHtR` im gleichen Datensatz.

3. Überprüfen Sie die Eingabe
:::

```{r}
#| label: WHtR-loesung

# 1. Graphik
gf_histogram(~ height_m, data = bodyfat, bins = 9)

# 2. WHtR berechnen
bodyfat <- bodyfat |> mutate(
  WHtR = waist/height_m)

# 3. überprüfen der Eingabe
head(bodyfat$WHtR)
```

### BMI

Der BMI ist heute das bekannteste Maß, um Übergewicht und Adipositas und damit einen erhöhten Körperfettanteil zu diagnostizieren, auch wenn dieser Wert Limitationen aufweist und als Parameter diskutiert wird.

Der BMI wird wie folgt berechnet:

```{r}
#| label: bmi

# BMI berechnen
bodyfat <- bodyfat |> mutate(
  bmi = weight_kg/height_m^2)

# überprüfen der Eingabe
head(bodyfat$bmi)

```

## Data-Subset generieren

Variablen, aus denen das Körperfett berechnet wurde, werden nicht mit in den Analysedatensatz genommen!

```{r}
#| label: remove_density

# Variablen löschen
bodyfat_siri <- bodyfat |> select(c(-Density, -bodyfat_brozeck))
str(bodyfat_siri)
```

# Modellierung

## Trainingsdaten erstellen

Die Daten werden zuerst in Trainings- und Testdaten aufgeteilt.
Diese Einteilung der Daten erlaubt es, die Leistung des Random-Forest-Algorithmus zu bewerten, indem der Algorithmus nach dem Training auf unbekannte Daten zur Evaluation der Generalisierbarkeit des Modells angewendet wird.
Dafür werden unter Nutzung der Funktion `createDataPartition()` aus dem `caret`-Paket zufällig 70% der Beobachtungen des Datensatzes in den Trainigsdatensatz gezogen und die restlichen 30% bilden den Testdatensatz.

```{r}
#| label: trainings-test-data

# Datenaufteilung in Trainings- und Testdaten
set.seed(42)
trainIndex <- createDataPartition(bodyfat$bodyfat_siri, p = 0.7, list = FALSE)
trainData <- bodyfat_siri[trainIndex, ]
testData <- bodyfat_siri[-trainIndex, ]

# Überblick über die aufgeteilten Daten
dim(trainData)
dim(testData)
```

## Trainineren des Modells

Vor dem Trainieren des Models muss beachtet werden, dass es sog. Hyperparameter gibt, die beim RF-Algorithmus eingestellt werden können.
Zu diesen Hyperparametern zählen unter anderem:

- `ntree:` gibt die Anzahl der Entscheigungsbäume im RF an.
Die Voreinstellung (default) ist 500.
- `mtry:` gibt die Anzahl der zufällig ausgewählten Prädiktorvariablen an jedem Split an.

Standardmäßig ist `mtry` auf $\sqrt{p}$ bei der Klassifikation und auf $\frac{p}{3}$ bei der Regression gesetzt -- sollen diese nicht geändert werden, muss `mtry` auch nicht angegeben werden.
($p$ ist die Anzahl der Prädiktorvariablen).

Das gleiche gilt für `ntree`, wenn die Voreinstellung (`ntree = 500`) nicht geändert werden soll, braucht der Parameter nicht angegeben zu werden.

```{r}
#| label: train-the-model

# Training des Random Forest Modells
set.seed(42)
rf_model1 <- randomForest(bodyfat_siri ~ ., data = trainData, 
                          importance = TRUE)

# Überblick über das Modell
rf_model1
```

## Testen des Modells

Im letzten Schritt hatte das Modell die Möglichkeit anhand des Trainingsdatensatzes Muster und Zusammenhänge in den Daten zu lernen.
Wie gut das dem Modell gelungen ist, kann überprüft werden, indem das Modell auf unbekannte Daten (Testdaten) zur Vorhersage angewendet wird:

```{r}
# Definition der Beobachteten Werte
observed <- testData$bodyfat_siri

# Vorhersage auf den Testdaten
predicted <- predict(rf_model1, testData)
head(predicted)
```

# Modellgüte

Wie gut sind die Vorhersagen des RF-Modells denn jetzt?

Um das herauszufinden, gibt es sogenannte Modellgütekriterien.
Diese Kriterien quantifizieren, wie weit die vorhergesagten Werte von den tatsächlichen Werten entfernt sind.
Beispiele für Modellgütekriterien bei der Klassifikation sind: Accuracy, Precision, Recall, F1-Score, ROC, AUC etc.
Da wir in dieser Fallstudie allerdings eine stetige Zielvariable untersuchen, konzentrieren wir uns auf Modellgütekriterien für die Regression.
Diese sind unter anderem: MSE, RMSE, MAE, $R^2$.

## MSE

Der MSE (Mean Squared Error) ist die mittlere quadratische Abweichung, auch mittlerer quadratischer Fehler genannt, zwischen dem vorhergesagten und dem wahren Wert.
Berechnet wird der MSE, indem die Differenz von vorhergesagten und wahren Wert quadriert, aufsummiert und dann durch die Anzahl der vorhergesagten Werte geteilt wird:

$$ 
  MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2
$$

Je größer das Ergebnis des MSE, desto größer sind die Vorhersagefehler, die vom Modell gemacht wurden.
Dementsprechend gilt, je kleiner das Ergebnis, desto besser das Modell.

## RMSE

Der RMSE (Root Mean Squared Error) ist die Wurzel des MSE.
Der RMSE hat gegenüber dem MSE den Vorteil, dass dieser besser zu interpretieren ist, da durch das Ziehen der Wurzel die Größe der Fehler wieder der Einheit der tatsächlichen Werte entspricht.

$$ 
  RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2} 
$$

## MAE

Der MAE (Mean Absolute Error) ist definiert als der Duchschnitt der absoluten Differenz zwischen vorhergesagten Wert und tatsächlichem Wert.
Wie beim MSE und RMSE gilt, je niedrieger der Wert des MAEs ist, desto kleiner sind die Fehler und desto besser ist das Modell.

$$ 
  MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y_i}| 
$$

::: {.callout-tip title="Aufgabe -- MSE, RMSE, MAE"}
- Worin unterscheiden sich MSE, RMSE und MAE?

  *Antwort:*\
  Der MAE ist im Vergleich zum MSE und RMSE robuster gegenüber Ausreißern und hat, ähnlich wie der RMSE, die gleiche Einheit wie die ursprünglichen Werte der Datentabelle, wodurch er besser zu interpretieren ist als der MSE.
  Allderdings bestraft der MAE große Fehler nicht so stark wie kleine Fehler und ist anders als der MSE und RMSE nicht differenzierbar, was eine Verwendung des MAEs für weitere mathematische Operationen nicht einfach macht.

:::

## $R^2$

Das $R^2$ gibt den Anteil der Varianz in der Zielvariable an, der durch das Modell erklärt wird.
Der Ergebnisraum reicht dabei von 0 bis 1, wobei höhere Werte eine bessere Leistung des Modells wiederspiegeln.

$$ 
  R^2 = 1 - \frac{RSS}{TSS} 
$$

Wobei:

- RSS (Residual Sum of Squares): $\sum_{i=1}^{n}(y_i - \hat{y_i})^2$
- TSS (Total Sum of Squares): $\sum_{i=1}^{n}(y_i - \overline{y})^2$

------------------------------------------------------------------------

::: {.callout-tip title="Frage -- Modellgüte"}
1. Berechnen Sie den MSE. Wie ist er sinnvoll zu interpretieren?

```{r}
#MSE 
mse <- mean((predicted - observed)^2) 
mse
```

MSE zeigt den quadrierten Fehler, die Einheit ist ebenfalls quadriert.
Die mittlere quadratische Abweichung zwischen dem vorhergesagten und dem tatsächlichen Körperfettanteil beträgt somit `r round(mse, 2)` $\%\text{-Punkte}^2$.

2. Das Ziehen der Wurzel ermöglicht eine einfachere Interpretation (RMSE).

```{r}
# RMSE
rmse <- sqrt(mse)
rmse
```

Im Mittel beträgt die Abweichung vom vorhergesagten und dem tatsächlichen Wert des Körperfettanteils `r round(sqrt(mse), 2)` %-Punkte.

3. Berechnen Sie den MAE. Ist eine Verwendung des MAE's hier sinnvoll?

```{r}
#MAE 
mae <- mean(abs(predicted - observed))
mae
```

Der MAE zeigt die tatsächliche durchschnittliche Abweichung, während der RMSE die weiter vom Mittelwert entfernten Werte stärker gewichtet.

4. Berechnen Sie das $R^2$ und interpretieren Sie es.

```{r}
# R2 
rss <- sum((predicted - observed) ^2) ## residual sum of squares 
tss <- sum((observed - mean(observed))^2)  ## total sum of squares 
rsq <- 1 - rss/tss
rsq
```

Es werden `r round(rsq*100, 0)` % der Varianz der Zielvariable durch das Modell erklärt.

5. Alle wesentlichen Gütemaße können mit der Funktion `postResample(model)` aus dem Paket `caret` ausgegeben werden. 
Nutzen Sie diese.

```{r}
# postResample
postResample(pred = predicted, obs = observed)
```
:::

# Modelloptimierung

Dem vorherigen Kapitel können wir entnehmen, wie gut das Model performt bspw.
wieviel der Varianz der Zielvariable erklärt wird.
Allerdings sind das die Ergebnisse eines Modells, bei welchem wir einfach die Standardeinstellungen der Hyperparameter übernommen haben.
Es gibt eine Möglichkeit diese Hyperparameter so einzustellen, dass unser Model noch bessere Vorhersagen macht: das Hyperparameter-Tuning.

Für das Tunen der Hyperparameter brauchen wir das `caret`-Paket.

## Grid-Search

Bei der Rastersuche oder Grid-Search werden alle möglichen Kombinationen der angegebenen Hyperparameterwerte ausprobiert, um das beste Modell zu finden.
Das beste Modell findet der RF-Algorithmus mit Hilfe der Kreuzvalidierung.

Mit dem Befehlt `method = "cv"` wird eine Kreuzvalidierung zur Optimierung des Modells durchgeführt.

**Vorgehen:**

* Der Trainingsdatensatz wird in $k$ gleich große Teilmengen geteilt.  
* Es erfolgt ein iteratives Training und Testen.  
* In jedem Durchlauf wir ein Testset verwendet und $k-1$ dienen als Trainingsdatensätze.  
* Ablauf wird $k$-fach ($k$-fold) wiederholt, so dass jeder Fold einmal als Testset fungiert.  

Um die Rechenzeit nicht zu groß werden zu lassen, tunen wir nur den mtry-Hyperparameter.
Legen wir los:

```{r}
# Hyperparameter-Tuning mit dem caret Paket
control <- trainControl(method = "cv", number = 5)
tuneGrid <- expand.grid(.mtry = c(2, 4, 6, 8, 10))

# Trainieren des Modells mit Hyperparameter-Tuning
set.seed(42)
rf_tuned <- train(bodyfat_siri ~ ., data = trainData, method = "rf", 
                  trControl = control, tuneGrid = tuneGrid)
rf_tuned

# Beste Parameter
best_mtry <- rf_tuned$bestTune$mtry
best_mtry

# Vorhersage auf den Testdaten mit dem getunten Modell
predicted_tuned <- predict(rf_tuned, testData)

# Berechnung der Vorhersagegenauigkeit des getunten Modells
postResample(pred = predicted_tuned, obs = observed)
```

Zum Abschluss können die Modellgütemaße des ersten Random Forest und dem getunten Modell verglichen werden:

```{r}
# Ursprungsmodell
postResample(pred = predicted, obs = observed)
# optimiertes Modell
postResample(pred = predicted_tuned, obs = observed)
```

Durch das Tunen der Hyperparameter wird der Vorhersagefehler etwas kleiner.

------------------------------------------------------------------------

# Wichtigkeit der Variablen

Zusätzlich können Sie sich ausgeben lassen, welche Variable bei der Vorhersage besonders relevant war und welche Variablen nicht so relevant gewesen sind.
Dabei bezieht sich die Relevanz einer Variable darauf, wie sehr ein bestimmtes Modell diese Variable *nutzt*, um möglichst genaue Vorhersagen zu treffen.
Je mehr ein Modell diese Variable *nutzt*, um Vorhersagen zu treffen, desto wichtiger ist sie für das Modell.

Lassen Sie uns die wichtigsten Variablen identifizieren, die das erste (nicht getunte) Modell verwendet hat, um die Vorhersagen zu treffen.

```{r}
# Wichtige Variablen
importance <- importance(rf_model1)
importance
```

`%IncMSE` (Percent Increase in MSE) bezieht sich auf die prozentuale Zunahme des MSE.
Ein hoher `%IncMSE` deutet auf eine wichtige Variable für die Vorhersagegenauigkeit des Modells hin.
`%IncMSE` erlaubt die Erstellung einer Rangordnung der Variablen im RF und der Identifizierung der einflussreichsten Prädiktoren im Modell.

```{r}
# Dataframe varImportance erstellen
varImportance <- data.frame(Variables = row.names(importance), 
                            Importance = importance[, 1])

# Importance Graphik
gf_col(Importance ~ reorder(Variables, Importance), 
       data = varImportance, fill = "darkblue") |>
  gf_refine(coord_flip()) |>
  gf_theme(theme_minimal()) |>
  gf_labs(title = "Variable Importance Modell 1", 
    x = "Variables", 
    y = "Importance")
```

------------------------------------------------------------------------

::: {.callout-tip title="Your Turn"}
Erstellen Sie ein Random Forest Modell mit der Berechnung nach Brozek (`body_fat_brozek`)

- Erstellen Sie einen Datensatz mit der Zielvariable `bodyfat_brozeck`.

```{r}
bodyfat_brozeck <- bodyfat |> select(c(-Density, -bodyfat_siri))
str(bodyfat_brozeck)
```

- Erstellen Sie einen Test- und Trainingsdatensatz.

```{r}
set.seed(42)
trainIndex <- createDataPartition(bodyfat$bodyfat_brozeck, p = 0.7, 
                                  list = FALSE)
trainData2 <- bodyfat_brozeck[trainIndex, ]
testData2 <- bodyfat_brozeck[-trainIndex, ]
```

- Erstellen Sie ein RF-Modell mit den Standardeinstellungen für die Hyperparameter.

```{r}
# Training des Random Forest Modells
set.seed(42)
rf_model2 <- randomForest(bodyfat_brozeck ~ ., 
                          data = trainData2, importance = TRUE)


# Überblick über das Modell
rf_model2
```

- Eruieren Sie die wichtigsten Variablen.

```{r}
# Wichtige Variablen
importance2 <- importance(rf_model2)

varImportance2 <- data.frame(Variables = row.names(importance2), 
                             Importance = importance2[, 1])

gf_col(Importance ~ reorder(Variables, Importance), 
       data = varImportance2, fill = "darkgreen") |>
  gf_refine(coord_flip()) |>
  gf_theme(theme_minimal()) |>
  gf_labs(title = "Variable Importance Modell2", 
    x = "Variables", 
    y = "Importance")
```

- Zeigt sich ein Unterschied in den Modellen bei den wichtigen Variablen und der MSE?

```{r}
# Modell 1
mse

#Modell 2 
observed2 <- testData2$bodyfat_brozeck
predicted2 <- predict(rf_model2, testData2)

mse2 <- mean(abs(predicted2 - observed2)^2) 
mse2
```
:::

Modell 2 zeigt einen höheren MSE, die Vorhersagegüte ist also schlechter.
Die Rangfolge der wichtigsten Variablen ist ähnlich, nur `waist` und `whr` sind unter den ersten fünf Variablen vertauscht.

------------------------------------------------------------------------

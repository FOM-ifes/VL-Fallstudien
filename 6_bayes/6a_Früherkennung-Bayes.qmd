---
title: "Früherkennung - Bayes"
lang: de
author: "Ihr Name"
date: today
format: 
  html:
    toc: true
    html-math-method: katex
  pdf:
    toc: true
    number-sections: false
    colorlinks: true
    papersize: a4
editor: 
  markdown: 
    wrap: 72
---

```{r}
#| label: setup
#| include: false
library(mosaic)
# Zufallszahlengenerator festlegen
set.seed(1896)
# Vektor für \pi bereitstellen
vpi <- seq(0,1, by = 1/1000)
#Priors
alpha_prior <- 1
beta_prior <- 1
```

## Zur Erinnerung

Diese Fallstudie ist eine Fortsetzung der Inferenz-Fallstudie zur
Früherkennung. In dieser wurden Sie gefragt:

-   Wie groß ist der Anteil $\pi$ der FOM-Studierenden, die die
    gestellte Frage[^1] richtig beantworten konnten?

-   Wie sicher sind Sie selbst in Bezug auf Ihre gegebene Antwort?

[^1]: Die Frage lautete: *Wie hoch ist die Wahrscheinlichkeit, bei einem
    positiven Testergebnis erkrankt zu sein?*

Das Ergebnis aus unserem Kurs lautete:

```{r}
# Anzahl Beobachtungen:
n <- 40
# Anzahl Richtige:
y <- 15
```

# Bayes'sche Analyse

Bisher haben wir ausschließlich die erhobenen Daten genutzt -- und nicht
unser Vorwissen!

> One way to understand rational, scientific thinking is via “Bayesian
> reasoning” which estimates the statistical probability of something
> being true and then updates that probability as new evidence appears,
> approaching the truth without achieving absolute certainty.

*Quelle*:
<https://bababrinkman.bandcamp.com/track/good-bayesian-feat-mc-lars-and-mega-ran>

Wir können unser *Wissen* über den Parameter in der Population $\pi$ mit
Hilfe des Satzes von Bayes anhand der Daten $n$ und $y$ aktualisieren!

**Bayes-Statistik**: Um auf Basis von Statistiken Aussagen über die
Wahrscheinlichkeiten von Parametern tätigen zu können, brauchen wir
zusätzlich eine *Priori*-Wahrscheinlichkeit $Pr({\pi})$:

$$\overbrace{Pr{(\pi} \mid {p})}^{\text{Posterior}} = Pr(\pi)\frac{Pr(p|\pi)}{Pr(p)}\propto \overbrace{Pr({\pi})}^{\text{Prior}} \cdot {\overbrace{Pr({p} \mid {\pi})}^{\text{Likelihood}}}$$

-   **Priori-Verteilung** $Pr({\pi})$: Wahrscheinlichkeitsverteilung von
    $\pi$, *bevor* wir unsere Daten haben.

-   **Likelihood** $Pr({p} \mid {\pi})$: *Mutmaßlichkeit* von $p$ bei
    gegebenem $\pi$.

-   **Posteriori-Verteilung** $Pr({\pi} \mid {p})$:
    Wahrscheinlichkeitsverteilung von $\pi$ *nachdem* wir unsere Daten
    haben.

## Beta-Binomial-Model

Für diese Analyse verwenden wir das **Beta-Binomial-Model**, welches
folgende Verteilungen nutzt:

-   **Priori-Verteilung**: Grundlage Beta-Verteilung mit Parametern:
    $\alpha_{prior}, \beta_{prior}$:
    $$\pi \sim Beta(\alpha_{prior}, \beta_{prior})$$

-   **Likelihood**: Grundlage Binomialverteilung mit Parametern $n$ und
    $\pi$: $$Y \sim Bin(n, \pi)$$

-   **Posteriori-Verteilung**: Beta-Verteilung mit Parametern:
    $\alpha_{post}, \beta_{post}$:
    $$\pi|_{(Y=y)} \sim Beta(\alpha_{post}, \beta_{post})$$ mit
    $$\alpha_{post} = \alpha_{prior} + y, \quad \beta_{post} = \beta_{prior} + n - y$$

Dabei gilt für die Dichtefunktion der **Betaverteilung**
($\pi \sim Beta(\alpha, \beta)$):

$$f(\pi) \propto \pi^{\alpha-1} \cdot (1-\pi)^{\beta-1}, \text{ für } \pi \in [0,1]$$

Und $\alpha > 0, \beta >0$ bestimmen die Form der Verteilung.
Desweiteren ergeben sich:

-   Erwartungswert (*Mittelwert* der Verteilung):
    $E(\pi)=\frac{\alpha}{\alpha+\beta}$,
-   Modus (Modalwert):
    $Modus(\pi)=\frac{\alpha-1}{\alpha+\beta-2}, \text{ für } \alpha, \beta > 1$
    und
-   Varianz:
    $Var(\pi)=\frac{\alpha \cdot \beta}{(\alpha+\beta)^2 \cdot (\alpha+\beta+1)}$.

## Priori-Verteilung

Die Parameter *Ihrer* Priori-Verteilung haben Sie oben festgelegt:
$$\alpha_{prior}=`r alpha_prior`, \beta_{prior}=`r beta_prior`$$

Und damit ergibt sich folgende Dichte:

```{r}
#| label: Prior-Verteilung

# Dichte
d_prior <- dbeta(vpi, shape1 = alpha_prior, shape2 = beta_prior)

# Visualisierung
gf_line(d_prior ~ vpi,
         color= "#D55E00", linewidth = 1.2) |>
  gf_labs(x = expression(pi), y = expression(f(pi)),
          title = paste0("Beta(", alpha_prior, ", " , beta_prior, ")"))
```

#### Fragen

-   Welche Verteilungsform hat *Ihre* Priori-Verteilung?

-   Gibt es keinen, einen oder zwei Modalwerte? Und wenn ja, wo liegen
    diese?

## Likelihood

Die Likelihood haben wir bereits in der klassisch-frequentistischen
Analyse betrachtet:

```{r}
#| label: Likelihood-Bayes

# Likelihood
like <- dbinom(y, n, vpi)

# Visualisierung
gf_line(like ~ vpi,
        color= "#CC79A7", linewidth = 1.2) |>
  gf_labs(x = expression(pi), y = expression(L(pi)), 
          title = paste0("n = ", n, " und y = " , y))
```

## Posterior-Verteilung

Wir aktualisieren jetzt unser Wissen (und unsere Unsicherheit) über
$\pi$:

```{r}
#| label: Posterior-Verteilung

# Posterior
alpha_post <- alpha_prior + y
beta_post <- beta_prior + n - y

# Dichte
d_post <- dbeta(vpi, shape1 = alpha_post, shape2 = beta_post)

# Visualisierung
gf_line(d_post ~ vpi,
         color= "#009E73", linewidth = 1.2) |>
  gf_labs(x = expression(pi), y = expression(f(pi)),
          title = paste0("Beta(", alpha_post, ", " , beta_post, ")"))
```

Wir können jetzt z. B. Modus oder Erwartungswert der Posteriorverteilung
berechnen:

```{r}
#| label: Posterior-Kennzahlen

# Erwartungswert
mittelwert_post <- alpha_post / (alpha_post + beta_post)
mittelwert_post
# Modus
modus_post <- (alpha_post-1) / (alpha_post + beta_post-2)
modus_post
```

Und es kann das **Kredibilitätsintervall** berechnet werden:

```{r}
#| label: Kredibilitätsintervall

# Kredibilitätsintervall
ki <- qbeta(c(0.025, 0.975), alpha_post, beta_post)

# Elemente benennen
names(ki) <- c("2.5% Quantil", "97.5% Quantil")

# ki ausgeben
ki
```

#### Fragen

-   Sind die Kennzahlen der Posteriori-Verteilung unabhängig von der
    Priori-Verteilung?

-   Wo liegt der Erwartungswert der Posteriori-Verteilung im Verhältnis
    zum Erwartungswert der Priori-Verteilung und dem entsprechenden Wert
    der Likelihood?

*Tipp*: Zur Beantwortung der ersten beiden Fragen können Sie auch gerne
wieder die App <https://fomshinyapps.shinyapps.io/BaBeBi/> nutzen!

-   Stimmt die Aussage: Auf Grundlage der Priori-Verteilung und einer
    Binomial-Verteilung der beobachteten Daten kann mit einer
    Wahrscheinlichkeit von 95% davon ausgegangen werden, dass der Anteil
    $\pi$ in der Zielpopulation zwischen `{r} floor(ki[1]*100)/100` und
    `{r} ceiling(ki[2]*100)/100` liegt?
